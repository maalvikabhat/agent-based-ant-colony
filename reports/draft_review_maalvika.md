### Question:  What is your understanding of the experiment the team is replicating?  What question does it answer?  How clear is the team's explanation?

I think the team did a good job of outlining their project in the abstract. I understand that the team is replicating a variation of the Sugarscape model that was covered in class--by adding a new component, illness, to the model. With illness being prone to spread with a higher probability in densely populated areas, the team wishes to observe whether the tendency to avoid illness or the tendency to acquire more sugar will overpower one another 

### Methodology: Do you understand the methodology?  Does it make sense for the question?  Are there limitations you see that the team did not address?

The methodology was understandable to me because I have taken Complexity Science, but I would have loved to have the "aid" part discussed in more depth, since I was confused about that. 

### Results: Do you understand what the results are (not yet considering their interpretation)?  If they are presented graphically, are the visualizations effective?  Do all figures have labels on the axes and captions?

The results were clear and I really appreciated the group explaining the figures in depth. I think a label of timesteps would have been helpful as well.

### Interpretation: Does the draft report interpret the results as an answer to the motivating question?  Does the argument hold water?

The interpretation of potential results definitely holds water and makes sense to me. From what I understand, there is a split of agents -- ones who prioritize sugar over health, and those who prioritize health over sugar.

### Replication: Are the results in the report consistent with the results from the original paper?  If so, how did the authors demonstrate that consistency?  Is it quantitative or qualitative?

From what I understand, the paper used as the primary source doesn't answer the question in the same field as the team, so the team's results would be separate from the source paper. The team's result seems qualitative as of now, because they are observing agent behavior that arises, not any specific measurement.

### Extension: Does the report explain an extension to the original experiment clearly?  Can it answer an interesting question that the original experiment did not answer?

Yes! The report answers an "interesting" question of divided priorities within agents and how that will affect agent behavior and the model.

### Progress: Is the team roughly where they should be at this point, with a replication that is substantially complete and an extension that is clearly defined and either complete or nearly so?

Yes, the team seems to be making great progress in understanding the paper, their problem statement, and making strides to make the final project a reality.

### Presentation: Is the report written in clear, concise, correct language?  Is it consistent with the audience and goals of the report?  Does it violate any of the recommendations in my style guideLinks to an external site.?

I think the report was easy to read and understand, clear and concise. As the target audience, I felt like it was written appropriately.

### Mechanics: Is the report in the right directory with the right file name?  Is it formatted professionally in Markdown?  Does it include a meaningful title and the full names of the authors?  Is the bibliography in an acceptable style? 

Yes. The only thing I would do differently is change the name of the report.
